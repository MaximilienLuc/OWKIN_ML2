{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Troubleshooting: Adversarial Validation & Distribution Shift Analysis\n",
    "This notebook diagnoses why the CV score (0.68) is much higher than Test score (0.61).\n",
    "We perform **Adversarial Validation** to check if Train and Test data distributions are different.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install xgboost joblib scikit-learn matplotlib pandas tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from xgboost import XGBClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading & Feature Extraction\n",
    "We reuse the efficient Joblib loading developed earlier.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path(\"Data\")\n",
    "train_features_dir = data_dir / \"train_input\" / \"moco_features\"\n",
    "test_features_dir = data_dir / \"test_input\" / \"moco_features\"\n",
    "df_train = pd.read_csv(data_dir  / \"supplementary_data\" / \"train_metadata.csv\")\n",
    "df_test = pd.read_csv(data_dir  / \"supplementary_data\" / \"test_metadata.csv\")\n",
    "\n",
    "def process_sample(sample_info, features_dir, is_train=True):\n",
    "    if is_train:\n",
    "        sample = sample_info[0]\n",
    "    else:\n",
    "        sample = sample_info\n",
    "        \n",
    "    _features = np.load(features_dir / sample)\n",
    "    # Discard coordinates, keep features\n",
    "    features = _features[:, 3:]\n",
    "    \n",
    "    # Standard Pooling (Mean, Std, Max)\n",
    "    mean_feat = np.mean(features, axis=0)\n",
    "    std_feat = np.std(features, axis=0)\n",
    "    max_feat = np.max(features, axis=0)\n",
    "    \n",
    "    return np.concatenate([mean_feat, std_feat, max_feat])\n",
    "\n",
    "print(\"Loading Train Data...\")\n",
    "X_train_list = Parallel(n_jobs=-1)(\n",
    "    delayed(process_sample)(row, train_features_dir, is_train=True) \n",
    "    for row in tqdm(df_train[[\"Sample ID\"]].values)\n",
    ")\n",
    "X_train = np.array(X_train_list)\n",
    "\n",
    "print(\"Loading Test Data...\")\n",
    "X_test_list = Parallel(n_jobs=-1)(\n",
    "    delayed(process_sample)(sample, test_features_dir, is_train=False)\n",
    "    for sample in tqdm(df_test[\"Sample ID\"].values)\n",
    ")\n",
    "X_test = np.array(X_test_list)\n",
    "\n",
    "print(f\"Train shape: {X_train.shape}, Test shape: {X_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adversarial Validation\n",
    "We try to distinguish Train vs Test samples. If the model can easily do this (AUC > 0.5), it means the features have a different distribution (Covariate Shift).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset for Adversarial Validation\n",
    "# 0 = Train, 1 = Test\n",
    "y_av_train = np.zeros(len(X_train))\n",
    "y_av_test = np.ones(len(X_test))\n",
    "\n",
    "X_av = np.vstack([X_train, X_test])\n",
    "y_av = np.concatenate([y_av_train, y_av_test])\n",
    "\n",
    "print(f\"Adversarial dataset shape: {X_av.shape}\")\n",
    "\n",
    "# Train XGBoost to distinguish Train from Test\n",
    "model_av = XGBClassifier(\n",
    "    n_estimators=50,\n",
    "    max_depth=4,\n",
    "    learning_rate=0.1,\n",
    "    eval_metric='auc',\n",
    "    use_label_encoder=False,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# 5-Fold Stratified CV\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scores = cross_val_score(model_av, X_av, y_av, cv=cv, scoring='roc_auc', n_jobs=-1)\n",
    "\n",
    "print(f\"Adversarial Validation AUC: {np.mean(scores):.3f} +/- {np.std(scores):.3f}\")\n",
    "\n",
    "if np.mean(scores) > 0.70:\n",
    "    print(\"WARNING: Significant distribution shift detected! The model can easily tell Train from Test.\")\n",
    "else:\n",
    "    print(\"Distribution shift seems moderate.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection based on Drift\n",
    "If drift is high, we can find the features responsible for it and remove them.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_av.fit(X_av, y_av)\n",
    "importance = model_av.feature_importances_\n",
    "indices = np.argsort(importance)[::-1]\n",
    "\n",
    "print(\"Top 20 Drifting Features (Indices):\")\n",
    "for f in range(20):\n",
    "    print(f\"{f+1}. Feature {indices[f]} ({importance[indices[f]]:.4f})\")\n",
    "\n",
    "# Suggest filtering\n",
    "drift_features = indices[:50] # Top 50 most different features\n",
    "print(f\"\\nSuggested action: Try removing these top drifting features from the main model.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}